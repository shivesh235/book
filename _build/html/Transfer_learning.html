

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Transfer Learning &#8212; Book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Transfer_learning';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Tensorflow" href="Tensorflow.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Tensorflow.html">Tensorflow</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Transfer Learning</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FTransfer_learning.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Transfer_learning.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Transfer Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">Feature Extraction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-dataset">Exploring Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-loader-preparing-the-data">Data loader (preparing the data)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-callbacks-things-to-run-whilst-our-model-train">Setting up callbacks (things to run whilst our model train</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-model-using-tensorflow-hub">Create model using TensorFlow Hub</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning">Fine Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experimentation">Experimentation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-1">Model 1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-2">Model 2</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="transfer-learning">
<h1>Transfer Learning<a class="headerlink" href="#transfer-learning" title="Permalink to this heading">#</a></h1>
<p>Transfer learning is using the weights of another model that is learned from another problem for our own problem.</p>
<p>There are two main benefits to using transfer learning:</p>
<ul class="simple">
<li><p>Can leverage an existing neural network architecture proven to work on problems similar to our own.</p></li>
<li><p>Can leverage a working neural network architecture which has already learned patterns on similar data to our own. This often results in achieving great results with less custom data.</p></li>
</ul>
<section id="feature-extraction">
<h2>Feature Extraction<a class="headerlink" href="#feature-extraction" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check gpu availablity</span>
<span class="o">!</span>nividia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/bin/bash: line 1: nividia-smi: command not found
</pre></div>
</div>
</div>
</div>
<section id="exploring-dataset">
<h3>Exploring Dataset<a class="headerlink" href="#exploring-dataset" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># # Get data (10% of 10 food classes from Foof101)</span>
<span class="c1"># import zipfile</span>

<span class="c1"># # Download the data</span>
<span class="c1"># !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip</span>

<span class="c1"># # Extract and save</span>
<span class="c1"># zipref = zipfile.ZipFile(&quot;10_food_classes_10_percent.zip&quot;)</span>
<span class="c1"># zipref.extractall(&quot;/content/drive/MyDrive/Colab Notebooks&quot;)</span>
<span class="c1"># zipref.close()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Walk through directories</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">for</span> <span class="n">dirpath</span><span class="p">,</span> <span class="n">dirnames</span><span class="p">,</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent&quot;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dirnames</span><span class="p">)</span><span class="si">}</span><span class="s1"> directories and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">)</span><span class="si">}</span><span class="s1"> images in </span><span class="si">{</span><span class="n">dirpath</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show random images</span>
<span class="n">dirpath</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/&#39;</span>
<span class="n">classname</span> <span class="o">=</span> <span class="s1">&#39;ramen/&#39;</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dirpath</span> <span class="o">+</span> <span class="n">classname</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">dirpath</span><span class="o">+</span><span class="n">classname</span><span class="o">+</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">files</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">line</span> <span class="mi">9</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">import</span> <span class="nn">random</span>
<span class="ne">----&gt; </span><span class="mi">9</span> <span class="n">files</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dirpath</span> <span class="o">+</span> <span class="n">classname</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">dirpath</span><span class="o">+</span><span class="n">classname</span><span class="o">+</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">files</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/ramen/&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="data-loader-preparing-the-data">
<h3>Data loader (preparing the data)<a class="headerlink" href="#data-loader-preparing-the-data" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load our images</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>

<span class="n">IMG_SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">train_dir</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train&#39;</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test&#39;</span>

<span class="n">train_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
<span class="n">test_datagen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Images&quot;</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
                                               <span class="n">target_size</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="p">,</span>
                                               <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                               <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Images&quot;</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">test_datagen</span><span class="o">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
                                             <span class="n">target_size</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="p">,</span>
                                             <span class="n">class_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                             <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Images
Found 7500 images belonging to 10 classes.
Testing Images
Found 2500 images belonging to 10 classes.
</pre></div>
</div>
</div>
</div>
</section>
<section id="setting-up-callbacks-things-to-run-whilst-our-model-train">
<h3>Setting up callbacks (things to run whilst our model train<a class="headerlink" href="#setting-up-callbacks-things-to-run-whilst-our-model-train" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a tensorboard callback</span>
<span class="kn">import</span> <span class="nn">datetime</span>

<span class="k">def</span> <span class="nf">create_tensorboard_callback</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">experiment_name</span><span class="p">):</span>
    <span class="n">log_dir</span> <span class="o">=</span> <span class="n">dir_name</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">experiment_name</span> <span class="o">+</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">-%H%M%S&#39;</span><span class="p">)</span>
    <span class="n">tensorboard_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Saving tensorboard log files to: </span><span class="si">{</span><span class="n">log_dir</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensorboard_callback</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="create-model-using-tensorflow-hub">
<h3>Create model using TensorFlow Hub<a class="headerlink" href="#create-model-using-tensorflow-hub" title="Permalink to this heading">#</a></h3>
<p>We can access various pretrained models on: <a class="reference external" href="https://www.tensorflow.org/hub">https://www.tensorflow.org/hub</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s compare following two models</span>
<span class="n">resnet_url</span> <span class="o">=</span> <span class="s1">&#39;https://www.kaggle.com/models/tensorflow/resnet-50/frameworks/TensorFlow2/variations/feature-vector/versions/1&#39;</span>

<span class="n">efficientnet_url</span> <span class="o">=</span> <span class="s1">&#39;https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import dependencies</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s make a function to create models from url&#39;s</span>
<span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">model_url</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Take a TensorFlow Hub url and create a Keras Sequential model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Download the pretrained model and save it as a Keras layer</span>
    <span class="n">feature_extraction_layer</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">model_url</span><span class="p">,</span>
                                              <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                              <span class="n">name</span><span class="o">=</span><span class="s1">&#39;feature_extraction_layer&#39;</span><span class="p">,</span>
                                              <span class="n">input_shape</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="o">+</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>

    <span class="c1"># Create our own model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">feature_extraction_layer</span><span class="p">,</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_layer&#39;</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create Resnet model</span>
<span class="n">resnet_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">resnet_url</span><span class="p">,</span>
                            <span class="n">num_classes</span><span class="o">=</span><span class="n">train_data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># Compile our model</span>
<span class="n">resnet_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
                     <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
                     <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resnet_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 feature_extraction_layer (  (None, 2048)              23561152  
 KerasLayer)                                                     
                                                                 
 output_layer (Dense)        (None, 10)                20490     
                                                                 
=================================================================
Total params: 23581642 (89.96 MB)
Trainable params: 20490 (80.04 KB)
Non-trainable params: 23561152 (89.88 MB)
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s fit our model on train data</span>
<span class="n">resnet_history</span> <span class="o">=</span> <span class="n">resnet_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                                  <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                  <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span>
                                  <span class="n">validation_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                                  <span class="n">validation_steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span>
                                  <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">create_tensorboard_callback</span><span class="p">(</span><span class="n">dir_name</span><span class="o">=</span><span class="s1">&#39;tf_hub&#39;</span><span class="p">,</span>
                                                                         <span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;resnet/&#39;</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving tensorboard log files to: tf_hub/resnet50-20240319-195831
Epoch 1/5
118/118 [==============================] - 2703s 23s/step - loss: 0.9426 - accuracy: 0.7004 - val_loss: 0.4407 - val_accuracy: 0.8604
Epoch 2/5
118/118 [==============================] - 64s 544ms/step - loss: 0.4935 - accuracy: 0.8423 - val_loss: 0.3851 - val_accuracy: 0.8760
Epoch 3/5
118/118 [==============================] - 65s 550ms/step - loss: 0.4045 - accuracy: 0.8743 - val_loss: 0.3540 - val_accuracy: 0.8860
Epoch 4/5
118/118 [==============================] - 65s 548ms/step - loss: 0.3520 - accuracy: 0.8873 - val_loss: 0.3453 - val_accuracy: 0.8892
Epoch 5/5
118/118 [==============================] - 64s 545ms/step - loss: 0.3122 - accuracy: 0.9032 - val_loss: 0.3458 - val_accuracy: 0.8820
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot our loss curves</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">plot_loss_curves</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
    <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>

    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Plot loss</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="c1"># Plot accuracy</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loss curves for resnet</span>
<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">resnet_history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fc280269edf8178cffdab975699526ace8ac8cf2f095a6358d1d006bfa2bf882.png" src="_images/fc280269edf8178cffdab975699526ace8ac8cf2f095a6358d1d006bfa2bf882.png" />
<img alt="_images/6b8bf1233ae2ee5b9fbccc6340a637ae49893c376d1bc07d4f214a9c62428c72.png" src="_images/6b8bf1233ae2ee5b9fbccc6340a637ae49893c376d1bc07d4f214a9c62428c72.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create EfficientNet model</span>
<span class="n">efficientnet_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">efficientnet_url</span><span class="p">,</span>
                                  <span class="n">num_classes</span><span class="o">=</span><span class="n">train_data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># Compile EfficientNet Model</span>
<span class="n">efficientnet_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
                           <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
                           <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># Fit our model to trining data</span>
<span class="n">efficientnet_history</span> <span class="o">=</span> <span class="n">efficientnet_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                                              <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                              <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span>
                                              <span class="n">validation_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                                              <span class="n">validation_steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span>
                                              <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">create_tensorboard_callback</span><span class="p">(</span><span class="n">dir_name</span><span class="o">=</span><span class="s1">&#39;tf_hub&#39;</span><span class="p">,</span>
                                                                                     <span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;efficientnet/&#39;</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving tensorboard log files to: tf_hub/efficientnet/20240319-204932
Epoch 1/5
118/118 [==============================] - 78s 558ms/step - loss: 0.9775 - accuracy: 0.7371 - val_loss: 0.4734 - val_accuracy: 0.8804
Epoch 2/5
118/118 [==============================] - 64s 538ms/step - loss: 0.5085 - accuracy: 0.8540 - val_loss: 0.3715 - val_accuracy: 0.8912
Epoch 3/5
118/118 [==============================] - 62s 524ms/step - loss: 0.4253 - accuracy: 0.8728 - val_loss: 0.3335 - val_accuracy: 0.9004
Epoch 4/5
118/118 [==============================] - 63s 531ms/step - loss: 0.3756 - accuracy: 0.8911 - val_loss: 0.3086 - val_accuracy: 0.9056
Epoch 5/5
118/118 [==============================] - 62s 522ms/step - loss: 0.3421 - accuracy: 0.8981 - val_loss: 0.2933 - val_accuracy: 0.9104
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loss curves for EfficientNet</span>
<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">efficientnet_history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/73836a21809a1349864a581e3be34a77012d92a42f81e44450ac5010b33cbd7f.png" src="_images/73836a21809a1349864a581e3be34a77012d92a42f81e44450ac5010b33cbd7f.png" />
<img alt="_images/a4bb024eb99ce12a9257ea7ce4e77f540f7d37c4206318c51e182b52e1266c07.png" src="_images/a4bb024eb99ce12a9257ea7ce4e77f540f7d37c4206318c51e182b52e1266c07.png" />
</div>
</div>
</section>
</section>
<section id="fine-tuning">
<h2>Fine Tuning<a class="headerlink" href="#fine-tuning" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Fine Tuning Transfer Learning Models</p></li>
<li><p>Using Keras Functional API</p></li>
<li><p>Use small dataset 10% to train faster</p></li>
<li><p>Data Augumentation</p></li>
<li><p>ModelCheckpoint callbacks</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.15.0
[PhysicalDevice(name=&#39;/physical_device:CPU:0&#39;, device_type=&#39;CPU&#39;)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s use 10% data of each class from our 10 food classes dataset</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">walk_through_dir</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Walks through dir_path returning its contents.</span>

<span class="sd">  Args:</span>
<span class="sd">    dir_path (str): target directory</span>

<span class="sd">  Returns:</span>
<span class="sd">    A print out of:</span>
<span class="sd">      number of subdiretories in dir_path</span>
<span class="sd">      number of images (files) in each subdirectory</span>
<span class="sd">      name of each subdirectory</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">for</span> <span class="n">dirpath</span><span class="p">,</span> <span class="n">dirnames</span><span class="p">,</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dirnames</span><span class="p">)</span><span class="si">}</span><span class="s2"> directories and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">)</span><span class="si">}</span><span class="s2"> images in &#39;</span><span class="si">{</span><span class="n">dirpath</span><span class="si">}</span><span class="s2">&#39;.&quot;</span><span class="p">)</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent&#39;</span>

<span class="c1"># Walk through our data dir</span>
<span class="n">walk_through_dir</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>There are 2 directories and 0 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent&#39;.
There are 10 directories and 0 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/ice_cream&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/chicken_curry&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/steak&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/sushi&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/chicken_wings&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/grilled_salmon&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/hamburger&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/pizza&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/ramen&#39;.
There are 0 directories and 250 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/test/fried_rice&#39;.
There are 10 directories and 0 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/ice_cream&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/chicken_curry&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/steak&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/sushi&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/chicken_wings&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/grilled_salmon&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/hamburger&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/pizza&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/ramen&#39;.
There are 0 directories and 75 images in &#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_10_percent/train/fried_rice&#39;.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create train and test dir paths</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="n">data_dir</span> <span class="o">+</span> <span class="s1">&#39;/train&#39;</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="n">data_dir</span> <span class="o">+</span> <span class="s1">&#39;/test&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s create tf.data.Dataset from image files in directory</span>
<span class="n">IMG_SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
                                                                 <span class="n">image_size</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="p">,</span>
                                                                 <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
                                                                <span class="n">image_size</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="p">,</span>
                                                                <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                                                <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 750 files belonging to 10 classes.
Found 2500 files belonging to 10 classes.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check class name</span>
<span class="n">train_data</span><span class="o">.</span><span class="n">class_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;chicken_curry&#39;,
 &#39;chicken_wings&#39;,
 &#39;fried_rice&#39;,
 &#39;grilled_salmon&#39;,
 &#39;hamburger&#39;,
 &#39;ice_cream&#39;,
 &#39;pizza&#39;,
 &#39;ramen&#39;,
 &#39;steak&#39;,
 &#39;sushi&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s see batch of our data</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_data</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(
[[[[1.60357147e+02 4.74285736e+01 2.01989803e+01]
   [1.68688782e+02 5.43775520e+01 2.32397957e+01]
   [1.80275513e+02 6.10612259e+01 2.69234695e+01]
   ...
   [1.07750336e+02 5.31176491e+01 5.61239958e-01]
   [1.84551529e+02 1.23265762e+02 5.81943207e+01]
   [1.94115814e+02 1.25345390e+02 6.03453903e+01]]

  [[1.78239807e+02 6.13826523e+01 2.73316345e+01]
   [1.77775497e+02 5.96479607e+01 2.39285717e+01]
   [1.76974487e+02 5.69438782e+01 1.99438801e+01]
   ...
   [1.29725006e+02 7.38117371e+01 1.70972290e+01]
   [2.19913300e+02 1.55627533e+02 9.35561142e+01]
   [1.68881363e+02 9.41670761e+01 3.58813629e+01]]

  [[1.61377548e+02 5.04438782e+01 1.78010216e+01]
   [1.62673462e+02 5.18163261e+01 1.84591846e+01]
   [1.61265305e+02 5.36224480e+01 1.89744892e+01]
   ...
   [1.61128433e+02 9.84396591e+01 4.29394798e+01]
   [2.28183228e+02 1.57397461e+02 9.87852402e+01]
   [1.50234055e+02 6.90911331e+01 1.80810204e+01]]

  ...

  [[1.45714722e+01 7.21426392e+00 3.57147217e+00]
   [1.47704315e+01 7.41322327e+00 4.19895935e+00]
   [1.60918064e+01 6.42850590e+00 5.68872738e+00]
   ...
   [2.49163437e+02 2.15637878e+02 1.54163437e+02]
   [2.46260254e+02 2.11903046e+02 1.53688782e+02]
   [2.47995010e+02 2.13637802e+02 1.57423538e+02]]

  [[1.20714417e+01 4.00000000e+00 2.21432495e+00]
   [1.30051165e+01 4.07144165e+00 5.00514317e+00]
   [1.40714417e+01 5.07144165e+00 8.07144165e+00]
   ...
   [2.41229385e+02 2.05285461e+02 1.42872238e+02]
   [2.37479507e+02 2.01479507e+02 1.41479507e+02]
   [2.32341980e+02 1.96341980e+02 1.38341980e+02]]

  [[1.37703857e+01 4.77038574e+00 7.77038574e+00]
   [1.33111572e+01 4.31115723e+00 9.21932602e+00]
   [1.29284668e+01 3.92846680e+00 8.92846680e+00]
   ...
   [2.35633286e+02 1.97556763e+02 1.34128235e+02]
   [2.30321838e+02 1.91321838e+02 1.32321838e+02]
   [2.35173553e+02 1.96173553e+02 1.39173553e+02]]]


 [[[6.74132614e+01 1.84846935e+01 2.71275520e+01]
   [6.82857132e+01 1.80000000e+01 2.46428566e+01]
   [7.32857208e+01 1.85714302e+01 2.47091846e+01]
   ...
   [8.81430511e+01 6.15765877e+01 4.52194443e+01]
   [8.41886139e+01 5.64080963e+01 3.98825531e+01]
   [6.17090721e+01 5.14643745e+01 3.10102539e+01]]

  [[7.52397995e+01 1.57397957e+01 2.75969391e+01]
   [7.66479645e+01 1.69336739e+01 2.68622456e+01]
   [7.70306168e+01 1.58724489e+01 2.40153065e+01]
   ...
   [1.08091827e+02 6.34080849e+01 5.02038116e+01]
   [1.03224533e+02 6.48062286e+01 4.83522339e+01]
   [1.07086731e+02 8.10613556e+01 7.85104370e+01]]

  [[8.04285736e+01 1.17857141e+01 2.50000000e+01]
   [8.12142868e+01 1.27857141e+01 2.53571434e+01]
   [8.15969391e+01 1.33061228e+01 2.42142868e+01]
   ...
   [7.58978271e+01 1.78571205e+01 5.58640575e+00]
   [7.48674774e+01 3.38828506e+01 1.88115540e+01]
   [1.19424332e+02 8.51999359e+01 9.92001038e+01]]

  ...

  [[2.07229263e+02 1.73653198e+02 2.40295990e+02]
   [1.80238968e+02 1.47336304e+02 2.14994400e+02]
   [1.89520050e+02 1.54969345e+02 2.24377426e+02]
   ...
   [1.68354869e-01 2.42601738e+01 7.87603226e+01]
   [0.00000000e+00 2.49133129e+01 8.11990814e+01]
   [5.05088627e-01 2.69286499e+01 8.33572083e+01]]

  [[1.68051056e+02 1.66051056e+02 2.29051056e+02]
   [1.79520172e+02 1.73673248e+02 2.37668137e+02]
   [1.54821671e+02 1.39178848e+02 2.04291077e+02]
   ...
   [7.14416504e-02 2.91428833e+01 8.93980331e+01]
   [5.10390941e-03 2.90765457e+01 9.12194290e+01]
   [7.14416504e-02 2.94745445e+01 9.16174240e+01]]

  [[1.72337158e+02 1.62622803e+02 2.27979980e+02]
   [1.66836884e+02 1.55571533e+02 2.21525620e+02]
   [1.83213516e+02 1.66417587e+02 2.30718552e+02]
   ...
   [1.71935260e+00 3.14183807e+01 9.68622665e+01]
   [1.78579712e+00 3.27857971e+01 9.77857971e+01]
   [3.84193134e+00 3.48419304e+01 9.98419342e+01]]]


 [[[1.01296562e+02 9.42965622e+01 5.22965546e+01]
   [1.03403061e+02 9.54030609e+01 5.93316345e+01]
   [1.08793365e+02 9.95790787e+01 7.10076523e+01]
   ...
   [2.35086231e+01 2.60172482e+01 1.04913759e+01]
   [2.64241199e+01 2.94241199e+01 1.10790854e+01]
   [2.63481789e+01 2.93481789e+01 1.03481798e+01]]

  [[1.07638718e+02 1.00601410e+02 5.87133293e+01]
   [1.07411354e+02 9.94113541e+01 6.33399239e+01]
   [1.12610970e+02 1.03409119e+02 7.47216263e+01]
   ...
   [1.94955559e+01 2.14955559e+01 7.55359268e+00]
   [2.49729214e+01 2.79190331e+01 1.10807009e+01]
   [2.89046574e+01 3.19046574e+01 1.49046574e+01]]

  [[1.09861603e+02 1.01946106e+02 6.26926041e+01]
   [1.16691010e+02 1.08691010e+02 7.26195831e+01]
   [1.18625000e+02 1.09625000e+02 7.90535736e+01]
   ...
   [1.32589502e+01 1.52589502e+01 2.25895023e+00]
   [2.06875381e+01 2.27044430e+01 9.36258698e+00]
   [2.58303909e+01 2.80669994e+01 1.33571777e+01]]

  ...

  [[2.45249786e+02 2.21776520e+02 1.69303253e+02]
   [2.24139099e+02 2.01139099e+02 1.50522980e+02]
   [2.16065994e+02 1.94280273e+02 1.46908417e+02]
   ...
   [7.91320343e+01 4.47601700e+01 1.71320305e+01]
   [7.73948364e+01 4.29215736e+01 1.53948393e+01]
   [8.47207184e+01 5.02474518e+01 2.34840832e+01]]

  [[2.42843521e+02 2.17843521e+02 1.63843521e+02]
   [2.26634140e+02 2.03499573e+02 1.51356720e+02]
   [2.19057816e+02 1.97272095e+02 1.48700668e+02]
   ...
   [7.86564026e+01 4.30849304e+01 1.66564026e+01]
   [7.88332520e+01 4.28332520e+01 1.68332539e+01]
   [8.31132507e+01 4.71132507e+01 2.11132507e+01]]

  [[1.77354950e+02 1.49808365e+02 9.95816498e+01]
   [2.12658463e+02 1.89444183e+02 1.39465240e+02]
   [2.37237717e+02 2.15960632e+02 1.69666626e+02]
   ...
   [7.87144165e+01 4.53572083e+01 1.79286804e+01]
   [8.24540634e+01 4.64540672e+01 2.04540653e+01]
   [7.44867477e+01 3.84867477e+01 1.24867468e+01]]]


 ...


 [[[2.53000000e+02 2.55000000e+02 2.54000000e+02]
   [2.52000000e+02 2.54000000e+02 2.53000000e+02]
   [2.53000000e+02 2.53000000e+02 2.51000000e+02]
   ...
   [2.52000000e+02 2.54000000e+02 2.53000000e+02]
   [2.52071442e+02 2.54071442e+02 2.53071442e+02]
   [2.54000000e+02 2.55000000e+02 2.55000000e+02]]

  [[2.53000000e+02 2.55000000e+02 2.54000000e+02]
   [2.52933670e+02 2.54933670e+02 2.53933670e+02]
   [2.53000000e+02 2.53000000e+02 2.51000000e+02]
   ...
   [2.52198959e+02 2.54198959e+02 2.53198959e+02]
   [2.52071442e+02 2.54071442e+02 2.53071442e+02]
   [2.53025513e+02 2.55000000e+02 2.54025513e+02]]

  [[2.54000000e+02 2.55000000e+02 2.55000000e+02]
   [2.53015305e+02 2.55000000e+02 2.54015305e+02]
   [2.54000000e+02 2.54000000e+02 2.52000000e+02]
   ...
   [2.53045914e+02 2.54831635e+02 2.54214279e+02]
   [2.52000000e+02 2.54000000e+02 2.53000000e+02]
   [2.52785721e+02 2.54785721e+02 2.51785721e+02]]

  ...

  [[2.51943878e+02 2.53785736e+02 2.55000000e+02]
   [2.50000015e+02 2.50000015e+02 2.48142883e+02]
   [2.52617340e+02 2.49280594e+02 2.44020401e+02]
   ...
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]]

  [[2.49571411e+02 2.54239792e+02 2.51142822e+02]
   [2.51142853e+02 2.52076523e+02 2.47209167e+02]
   [2.50586777e+02 2.47372482e+02 2.39831650e+02]
   ...
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]]

  [[2.51127594e+02 2.55000000e+02 2.50127594e+02]
   [2.50836700e+02 2.51836700e+02 2.45882614e+02]
   [2.51142715e+02 2.47928436e+02 2.38928436e+02]
   ...
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]
   [2.54000000e+02 2.54000000e+02 2.54000000e+02]]]


 [[[1.10714287e+02 1.11714287e+02 1.05714287e+02]
   [1.11285713e+02 1.14285713e+02 1.07285713e+02]
   [1.08505104e+02 1.13076530e+02 1.06076530e+02]
   ...
   [1.54204071e+02 1.68204071e+02 1.69204071e+02]
   [1.50193817e+02 1.64193817e+02 1.65193817e+02]
   [1.53729568e+02 1.69729568e+02 1.69729568e+02]]

  [[1.10714287e+02 1.11714287e+02 1.05714287e+02]
   [1.09928566e+02 1.12928566e+02 1.05928566e+02]
   [1.07285713e+02 1.11857140e+02 1.04857140e+02]
   ...
   [1.60984695e+02 1.71556137e+02 1.72301025e+02]
   [1.59999985e+02 1.72142838e+02 1.72214264e+02]
   [1.57520416e+02 1.69663269e+02 1.69734695e+02]]

  [[1.12219383e+02 1.13219383e+02 1.07219383e+02]
   [1.11285713e+02 1.14285713e+02 1.07285713e+02]
   [1.07857147e+02 1.12428574e+02 1.05428574e+02]
   ...
   [1.36857162e+02 1.37831650e+02 1.37765335e+02]
   [1.40484726e+02 1.40841873e+02 1.42627594e+02]
   [1.37142868e+02 1.37500015e+02 1.39285721e+02]]

  ...

  [[1.60291000e+02 1.71648209e+02 1.50576767e+02]
   [1.71602127e+02 1.83673645e+02 1.65745087e+02]
   [1.80714325e+02 1.93597046e+02 1.80168503e+02]
   ...
   [1.08407738e+02 3.78875618e+01 3.79334755e+01]
   [9.46777191e+01 2.97953644e+01 3.29943581e+01]
   [1.04515045e+02 4.24387665e+01 4.97244720e+01]]

  [[1.75076462e+02 1.88719315e+02 1.66790741e+02]
   [1.80515320e+02 1.97443893e+02 1.79949020e+02]
   [1.87183746e+02 2.06270477e+02 1.96627655e+02]
   ...
   [6.38212395e+01 1.45560408e+01 1.42244673e+01]
   [5.42803612e+01 1.54948368e+01 2.02806339e+01]
   [4.53365517e+01 1.36938219e+01 2.40509701e+01]]

  [[1.78250443e+02 1.89204453e+02 1.71092285e+02]
   [1.84301117e+02 1.97709213e+02 1.86183807e+02]
   [1.89642792e+02 2.06943726e+02 2.03295868e+02]
   ...
   [5.63268051e+01 1.71075668e+01 1.95463543e+01]
   [3.06327629e+01 7.34724045e+00 1.64851990e+01]
   [2.74079075e+01 1.24640608e+01 2.61529293e+01]]]


 [[[2.00000000e+00 2.00000000e+00 0.00000000e+00]
   [1.07142830e+00 1.07142830e+00 0.00000000e+00]
   [1.00000000e+00 1.00000000e+00 0.00000000e+00]
   ...
   [1.87857361e+01 9.78573608e+00 2.78573608e+00]
   [1.85714149e+01 9.57141590e+00 2.57141542e+00]
   [1.66428566e+01 7.64285707e+00 6.42857194e-01]]

  [[2.00000000e+00 2.00000000e+00 0.00000000e+00]
   [1.07142830e+00 1.07142830e+00 0.00000000e+00]
   [1.00000000e+00 1.00000000e+00 0.00000000e+00]
   ...
   [1.87857361e+01 9.78573608e+00 2.78573608e+00]
   [2.08571301e+01 1.18571301e+01 4.85713005e+00]
   [1.95713940e+01 1.05713940e+01 3.57139397e+00]]

  [[2.00000000e+00 2.00000000e+00 0.00000000e+00]
   [1.07142830e+00 1.07142830e+00 0.00000000e+00]
   [1.00000000e+00 1.00000000e+00 0.00000000e+00]
   ...
   [2.00000229e+01 1.07857361e+01 1.78573608e+00]
   [2.09285583e+01 1.17142725e+01 2.71427250e+00]
   [1.90000000e+01 9.78571415e+00 7.85714149e-01]]

  ...

  [[1.67285721e+02 1.59285721e+02 1.56285721e+02]
   [1.68198959e+02 1.63198959e+02 1.59198959e+02]
   [1.65785690e+02 1.63214264e+02 1.58214264e+02]
   ...
   [7.13060837e+01 3.73060837e+01 9.52034569e+00]
   [7.08009186e+01 3.68009224e+01 1.02294493e+01]
   [7.08469086e+01 3.68469086e+01 1.02754364e+01]]

  [[1.68239792e+02 1.61239792e+02 1.55239792e+02]
   [1.67066330e+02 1.62066330e+02 1.56066330e+02]
   [1.65015305e+02 1.62015305e+02 1.55015305e+02]
   ...
   [7.54438934e+01 4.04438972e+01 1.20153685e+01]
   [7.49387665e+01 3.99387665e+01 1.19387665e+01]
   [7.67602768e+01 4.17602806e+01 1.37602797e+01]]

  [[1.63928497e+02 1.58928497e+02 1.52928497e+02]
   [1.64642822e+02 1.59642822e+02 1.53642822e+02]
   [1.64352036e+02 1.61352036e+02 1.54352036e+02]
   ...
   [6.91479111e+01 3.41479111e+01 4.14791107e+00]
   [7.30969620e+01 3.80969582e+01 1.00969591e+01]
   [7.38724213e+01 3.88724251e+01 1.08724241e+01]]]], shape=(64, 224, 224, 3), dtype=float32) tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]], shape=(64, 10), dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a transfer learning model using Functional API(more flexible)</span>

<span class="c1"># 1. Create base model</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">EfficientNetB0</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 2. Freeze the base model</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># 3. Create inputs into our model</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="o">+</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_layer&#39;</span><span class="p">)</span>

<span class="c1"># 4. Add normalization layer</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>

<span class="c1"># 5. Pass inputs to base model</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># 6. Average pool outputs of base model</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;global_avg_pooling_layer&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># 7. Create output activation layer</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_layer&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># 8. Combine inputs and outputs into a model</span>
<span class="n">model_0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

<span class="c1"># 9. Compile the model</span>
<span class="n">model_0</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># 10. Fit the model</span>
<span class="n">history_0</span> <span class="o">=</span> <span class="n">model_0</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span>
                        <span class="n">validation_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                        <span class="n">validation_steps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.25</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(None, 7, 7, 1280)
(None, 1280)
Epoch 1/5
12/12 [==============================] - 401s 35s/step - loss: 2.0765 - accuracy: 0.2640 - val_loss: 1.6545 - val_accuracy: 0.5750
Epoch 2/5
12/12 [==============================] - 130s 11s/step - loss: 1.4351 - accuracy: 0.6720 - val_loss: 1.2235 - val_accuracy: 0.7312
Epoch 3/5
12/12 [==============================] - 150s 13s/step - loss: 1.0673 - accuracy: 0.7800 - val_loss: 0.8890 - val_accuracy: 0.8234
Epoch 4/5
12/12 [==============================] - 148s 13s/step - loss: 0.8586 - accuracy: 0.8107 - val_loss: 0.7750 - val_accuracy: 0.8250
Epoch 5/5
12/12 [==============================] - 163s 13s/step - loss: 0.7296 - accuracy: 0.8413 - val_loss: 0.6948 - val_accuracy: 0.8422
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_0</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;base_model&#39;</span><span class="p">,</span> <span class="n">save_format</span><span class="o">=</span><span class="s1">&#39;h5&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save(&#39;my_model.keras&#39;)`.
  saving_api.save_model(
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loaded_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;base_model&#39;</span><span class="p">)</span>
<span class="n">loaded_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>40/40 [==============================] - 337s 8s/step - loss: 0.6895 - accuracy: 0.8428
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.6894992589950562, 0.8428000211715698]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_0</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>40/40 [==============================] - 231s 6s/step - loss: 0.6895 - accuracy: 0.8428
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.6894991397857666, 0.8428000211715698]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check layers in our base model</span>
<span class="k">for</span> <span class="n">layer_no</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">base_model</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">layer_no</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0 input_4
1 rescaling_7
2 normalization_3
3 rescaling_8
4 stem_conv_pad
5 stem_conv
6 stem_bn
7 stem_activation
8 block1a_dwconv
9 block1a_bn
10 block1a_activation
11 block1a_se_squeeze
12 block1a_se_reshape
13 block1a_se_reduce
14 block1a_se_expand
15 block1a_se_excite
16 block1a_project_conv
17 block1a_project_bn
18 block2a_expand_conv
19 block2a_expand_bn
20 block2a_expand_activation
21 block2a_dwconv_pad
22 block2a_dwconv
23 block2a_bn
24 block2a_activation
25 block2a_se_squeeze
26 block2a_se_reshape
27 block2a_se_reduce
28 block2a_se_expand
29 block2a_se_excite
30 block2a_project_conv
31 block2a_project_bn
32 block2b_expand_conv
33 block2b_expand_bn
34 block2b_expand_activation
35 block2b_dwconv
36 block2b_bn
37 block2b_activation
38 block2b_se_squeeze
39 block2b_se_reshape
40 block2b_se_reduce
41 block2b_se_expand
42 block2b_se_excite
43 block2b_project_conv
44 block2b_project_bn
45 block2b_drop
46 block2b_add
47 block3a_expand_conv
48 block3a_expand_bn
49 block3a_expand_activation
50 block3a_dwconv_pad
51 block3a_dwconv
52 block3a_bn
53 block3a_activation
54 block3a_se_squeeze
55 block3a_se_reshape
56 block3a_se_reduce
57 block3a_se_expand
58 block3a_se_excite
59 block3a_project_conv
60 block3a_project_bn
61 block3b_expand_conv
62 block3b_expand_bn
63 block3b_expand_activation
64 block3b_dwconv
65 block3b_bn
66 block3b_activation
67 block3b_se_squeeze
68 block3b_se_reshape
69 block3b_se_reduce
70 block3b_se_expand
71 block3b_se_excite
72 block3b_project_conv
73 block3b_project_bn
74 block3b_drop
75 block3b_add
76 block4a_expand_conv
77 block4a_expand_bn
78 block4a_expand_activation
79 block4a_dwconv_pad
80 block4a_dwconv
81 block4a_bn
82 block4a_activation
83 block4a_se_squeeze
84 block4a_se_reshape
85 block4a_se_reduce
86 block4a_se_expand
87 block4a_se_excite
88 block4a_project_conv
89 block4a_project_bn
90 block4b_expand_conv
91 block4b_expand_bn
92 block4b_expand_activation
93 block4b_dwconv
94 block4b_bn
95 block4b_activation
96 block4b_se_squeeze
97 block4b_se_reshape
98 block4b_se_reduce
99 block4b_se_expand
100 block4b_se_excite
101 block4b_project_conv
102 block4b_project_bn
103 block4b_drop
104 block4b_add
105 block4c_expand_conv
106 block4c_expand_bn
107 block4c_expand_activation
108 block4c_dwconv
109 block4c_bn
110 block4c_activation
111 block4c_se_squeeze
112 block4c_se_reshape
113 block4c_se_reduce
114 block4c_se_expand
115 block4c_se_excite
116 block4c_project_conv
117 block4c_project_bn
118 block4c_drop
119 block4c_add
120 block5a_expand_conv
121 block5a_expand_bn
122 block5a_expand_activation
123 block5a_dwconv
124 block5a_bn
125 block5a_activation
126 block5a_se_squeeze
127 block5a_se_reshape
128 block5a_se_reduce
129 block5a_se_expand
130 block5a_se_excite
131 block5a_project_conv
132 block5a_project_bn
133 block5b_expand_conv
134 block5b_expand_bn
135 block5b_expand_activation
136 block5b_dwconv
137 block5b_bn
138 block5b_activation
139 block5b_se_squeeze
140 block5b_se_reshape
141 block5b_se_reduce
142 block5b_se_expand
143 block5b_se_excite
144 block5b_project_conv
145 block5b_project_bn
146 block5b_drop
147 block5b_add
148 block5c_expand_conv
149 block5c_expand_bn
150 block5c_expand_activation
151 block5c_dwconv
152 block5c_bn
153 block5c_activation
154 block5c_se_squeeze
155 block5c_se_reshape
156 block5c_se_reduce
157 block5c_se_expand
158 block5c_se_excite
159 block5c_project_conv
160 block5c_project_bn
161 block5c_drop
162 block5c_add
163 block6a_expand_conv
164 block6a_expand_bn
165 block6a_expand_activation
166 block6a_dwconv_pad
167 block6a_dwconv
168 block6a_bn
169 block6a_activation
170 block6a_se_squeeze
171 block6a_se_reshape
172 block6a_se_reduce
173 block6a_se_expand
174 block6a_se_excite
175 block6a_project_conv
176 block6a_project_bn
177 block6b_expand_conv
178 block6b_expand_bn
179 block6b_expand_activation
180 block6b_dwconv
181 block6b_bn
182 block6b_activation
183 block6b_se_squeeze
184 block6b_se_reshape
185 block6b_se_reduce
186 block6b_se_expand
187 block6b_se_excite
188 block6b_project_conv
189 block6b_project_bn
190 block6b_drop
191 block6b_add
192 block6c_expand_conv
193 block6c_expand_bn
194 block6c_expand_activation
195 block6c_dwconv
196 block6c_bn
197 block6c_activation
198 block6c_se_squeeze
199 block6c_se_reshape
200 block6c_se_reduce
201 block6c_se_expand
202 block6c_se_excite
203 block6c_project_conv
204 block6c_project_bn
205 block6c_drop
206 block6c_add
207 block6d_expand_conv
208 block6d_expand_bn
209 block6d_expand_activation
210 block6d_dwconv
211 block6d_bn
212 block6d_activation
213 block6d_se_squeeze
214 block6d_se_reshape
215 block6d_se_reduce
216 block6d_se_expand
217 block6d_se_excite
218 block6d_project_conv
219 block6d_project_bn
220 block6d_drop
221 block6d_add
222 block7a_expand_conv
223 block7a_expand_bn
224 block7a_expand_activation
225 block7a_dwconv
226 block7a_bn
227 block7a_activation
228 block7a_se_squeeze
229 block7a_se_reshape
230 block7a_se_reduce
231 block7a_se_expand
232 block7a_se_excite
233 block7a_project_conv
234 block7a_project_bn
235 top_conv
236 top_bn
237 top_activation
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check summary of our base model</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;efficientnetb0&quot;
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_4 (InputLayer)        [(None, None, None, 3)]      0         []                            
                                                                                                  
 rescaling_7 (Rescaling)     (None, None, None, 3)        0         [&#39;input_4[0][0]&#39;]             
                                                                                                  
 normalization_3 (Normaliza  (None, None, None, 3)        7         [&#39;rescaling_7[0][0]&#39;]         
 tion)                                                                                            
                                                                                                  
 rescaling_8 (Rescaling)     (None, None, None, 3)        0         [&#39;normalization_3[0][0]&#39;]     
                                                                                                  
 stem_conv_pad (ZeroPadding  (None, None, None, 3)        0         [&#39;rescaling_8[0][0]&#39;]         
 2D)                                                                                              
                                                                                                  
 stem_conv (Conv2D)          (None, None, None, 32)       864       [&#39;stem_conv_pad[0][0]&#39;]       
                                                                                                  
 stem_bn (BatchNormalizatio  (None, None, None, 32)       128       [&#39;stem_conv[0][0]&#39;]           
 n)                                                                                               
                                                                                                  
 stem_activation (Activatio  (None, None, None, 32)       0         [&#39;stem_bn[0][0]&#39;]             
 n)                                                                                               
                                                                                                  
 block1a_dwconv (DepthwiseC  (None, None, None, 32)       288       [&#39;stem_activation[0][0]&#39;]     
 onv2D)                                                                                           
                                                                                                  
 block1a_bn (BatchNormaliza  (None, None, None, 32)       128       [&#39;block1a_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block1a_activation (Activa  (None, None, None, 32)       0         [&#39;block1a_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block1a_se_squeeze (Global  (None, 32)                   0         [&#39;block1a_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block1a_se_reshape (Reshap  (None, 1, 1, 32)             0         [&#39;block1a_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block1a_se_reduce (Conv2D)  (None, 1, 1, 8)              264       [&#39;block1a_se_reshape[0][0]&#39;]  
                                                                                                  
 block1a_se_expand (Conv2D)  (None, 1, 1, 32)             288       [&#39;block1a_se_reduce[0][0]&#39;]   
                                                                                                  
 block1a_se_excite (Multipl  (None, None, None, 32)       0         [&#39;block1a_activation[0][0]&#39;,  
 y)                                                                  &#39;block1a_se_expand[0][0]&#39;]   
                                                                                                  
 block1a_project_conv (Conv  (None, None, None, 16)       512       [&#39;block1a_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block1a_project_bn (BatchN  (None, None, None, 16)       64        [&#39;block1a_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block2a_expand_conv (Conv2  (None, None, None, 96)       1536      [&#39;block1a_project_bn[0][0]&#39;]  
 D)                                                                                               
                                                                                                  
 block2a_expand_bn (BatchNo  (None, None, None, 96)       384       [&#39;block2a_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block2a_expand_activation   (None, None, None, 96)       0         [&#39;block2a_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block2a_dwconv_pad (ZeroPa  (None, None, None, 96)       0         [&#39;block2a_expand_activation[0]
 dding2D)                                                           [0]&#39;]                         
                                                                                                  
 block2a_dwconv (DepthwiseC  (None, None, None, 96)       864       [&#39;block2a_dwconv_pad[0][0]&#39;]  
 onv2D)                                                                                           
                                                                                                  
 block2a_bn (BatchNormaliza  (None, None, None, 96)       384       [&#39;block2a_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block2a_activation (Activa  (None, None, None, 96)       0         [&#39;block2a_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block2a_se_squeeze (Global  (None, 96)                   0         [&#39;block2a_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block2a_se_reshape (Reshap  (None, 1, 1, 96)             0         [&#39;block2a_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block2a_se_reduce (Conv2D)  (None, 1, 1, 4)              388       [&#39;block2a_se_reshape[0][0]&#39;]  
                                                                                                  
 block2a_se_expand (Conv2D)  (None, 1, 1, 96)             480       [&#39;block2a_se_reduce[0][0]&#39;]   
                                                                                                  
 block2a_se_excite (Multipl  (None, None, None, 96)       0         [&#39;block2a_activation[0][0]&#39;,  
 y)                                                                  &#39;block2a_se_expand[0][0]&#39;]   
                                                                                                  
 block2a_project_conv (Conv  (None, None, None, 24)       2304      [&#39;block2a_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block2a_project_bn (BatchN  (None, None, None, 24)       96        [&#39;block2a_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block2b_expand_conv (Conv2  (None, None, None, 144)      3456      [&#39;block2a_project_bn[0][0]&#39;]  
 D)                                                                                               
                                                                                                  
 block2b_expand_bn (BatchNo  (None, None, None, 144)      576       [&#39;block2b_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block2b_expand_activation   (None, None, None, 144)      0         [&#39;block2b_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block2b_dwconv (DepthwiseC  (None, None, None, 144)      1296      [&#39;block2b_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block2b_bn (BatchNormaliza  (None, None, None, 144)      576       [&#39;block2b_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block2b_activation (Activa  (None, None, None, 144)      0         [&#39;block2b_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block2b_se_squeeze (Global  (None, 144)                  0         [&#39;block2b_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block2b_se_reshape (Reshap  (None, 1, 1, 144)            0         [&#39;block2b_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block2b_se_reduce (Conv2D)  (None, 1, 1, 6)              870       [&#39;block2b_se_reshape[0][0]&#39;]  
                                                                                                  
 block2b_se_expand (Conv2D)  (None, 1, 1, 144)            1008      [&#39;block2b_se_reduce[0][0]&#39;]   
                                                                                                  
 block2b_se_excite (Multipl  (None, None, None, 144)      0         [&#39;block2b_activation[0][0]&#39;,  
 y)                                                                  &#39;block2b_se_expand[0][0]&#39;]   
                                                                                                  
 block2b_project_conv (Conv  (None, None, None, 24)       3456      [&#39;block2b_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block2b_project_bn (BatchN  (None, None, None, 24)       96        [&#39;block2b_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block2b_drop (Dropout)      (None, None, None, 24)       0         [&#39;block2b_project_bn[0][0]&#39;]  
                                                                                                  
 block2b_add (Add)           (None, None, None, 24)       0         [&#39;block2b_drop[0][0]&#39;,        
                                                                     &#39;block2a_project_bn[0][0]&#39;]  
                                                                                                  
 block3a_expand_conv (Conv2  (None, None, None, 144)      3456      [&#39;block2b_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block3a_expand_bn (BatchNo  (None, None, None, 144)      576       [&#39;block3a_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block3a_expand_activation   (None, None, None, 144)      0         [&#39;block3a_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block3a_dwconv_pad (ZeroPa  (None, None, None, 144)      0         [&#39;block3a_expand_activation[0]
 dding2D)                                                           [0]&#39;]                         
                                                                                                  
 block3a_dwconv (DepthwiseC  (None, None, None, 144)      3600      [&#39;block3a_dwconv_pad[0][0]&#39;]  
 onv2D)                                                                                           
                                                                                                  
 block3a_bn (BatchNormaliza  (None, None, None, 144)      576       [&#39;block3a_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block3a_activation (Activa  (None, None, None, 144)      0         [&#39;block3a_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block3a_se_squeeze (Global  (None, 144)                  0         [&#39;block3a_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block3a_se_reshape (Reshap  (None, 1, 1, 144)            0         [&#39;block3a_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block3a_se_reduce (Conv2D)  (None, 1, 1, 6)              870       [&#39;block3a_se_reshape[0][0]&#39;]  
                                                                                                  
 block3a_se_expand (Conv2D)  (None, 1, 1, 144)            1008      [&#39;block3a_se_reduce[0][0]&#39;]   
                                                                                                  
 block3a_se_excite (Multipl  (None, None, None, 144)      0         [&#39;block3a_activation[0][0]&#39;,  
 y)                                                                  &#39;block3a_se_expand[0][0]&#39;]   
                                                                                                  
 block3a_project_conv (Conv  (None, None, None, 40)       5760      [&#39;block3a_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block3a_project_bn (BatchN  (None, None, None, 40)       160       [&#39;block3a_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block3b_expand_conv (Conv2  (None, None, None, 240)      9600      [&#39;block3a_project_bn[0][0]&#39;]  
 D)                                                                                               
                                                                                                  
 block3b_expand_bn (BatchNo  (None, None, None, 240)      960       [&#39;block3b_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block3b_expand_activation   (None, None, None, 240)      0         [&#39;block3b_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block3b_dwconv (DepthwiseC  (None, None, None, 240)      6000      [&#39;block3b_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block3b_bn (BatchNormaliza  (None, None, None, 240)      960       [&#39;block3b_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block3b_activation (Activa  (None, None, None, 240)      0         [&#39;block3b_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block3b_se_squeeze (Global  (None, 240)                  0         [&#39;block3b_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block3b_se_reshape (Reshap  (None, 1, 1, 240)            0         [&#39;block3b_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block3b_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      [&#39;block3b_se_reshape[0][0]&#39;]  
                                                                                                  
 block3b_se_expand (Conv2D)  (None, 1, 1, 240)            2640      [&#39;block3b_se_reduce[0][0]&#39;]   
                                                                                                  
 block3b_se_excite (Multipl  (None, None, None, 240)      0         [&#39;block3b_activation[0][0]&#39;,  
 y)                                                                  &#39;block3b_se_expand[0][0]&#39;]   
                                                                                                  
 block3b_project_conv (Conv  (None, None, None, 40)       9600      [&#39;block3b_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block3b_project_bn (BatchN  (None, None, None, 40)       160       [&#39;block3b_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block3b_drop (Dropout)      (None, None, None, 40)       0         [&#39;block3b_project_bn[0][0]&#39;]  
                                                                                                  
 block3b_add (Add)           (None, None, None, 40)       0         [&#39;block3b_drop[0][0]&#39;,        
                                                                     &#39;block3a_project_bn[0][0]&#39;]  
                                                                                                  
 block4a_expand_conv (Conv2  (None, None, None, 240)      9600      [&#39;block3b_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block4a_expand_bn (BatchNo  (None, None, None, 240)      960       [&#39;block4a_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block4a_expand_activation   (None, None, None, 240)      0         [&#39;block4a_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block4a_dwconv_pad (ZeroPa  (None, None, None, 240)      0         [&#39;block4a_expand_activation[0]
 dding2D)                                                           [0]&#39;]                         
                                                                                                  
 block4a_dwconv (DepthwiseC  (None, None, None, 240)      2160      [&#39;block4a_dwconv_pad[0][0]&#39;]  
 onv2D)                                                                                           
                                                                                                  
 block4a_bn (BatchNormaliza  (None, None, None, 240)      960       [&#39;block4a_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block4a_activation (Activa  (None, None, None, 240)      0         [&#39;block4a_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block4a_se_squeeze (Global  (None, 240)                  0         [&#39;block4a_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block4a_se_reshape (Reshap  (None, 1, 1, 240)            0         [&#39;block4a_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block4a_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      [&#39;block4a_se_reshape[0][0]&#39;]  
                                                                                                  
 block4a_se_expand (Conv2D)  (None, 1, 1, 240)            2640      [&#39;block4a_se_reduce[0][0]&#39;]   
                                                                                                  
 block4a_se_excite (Multipl  (None, None, None, 240)      0         [&#39;block4a_activation[0][0]&#39;,  
 y)                                                                  &#39;block4a_se_expand[0][0]&#39;]   
                                                                                                  
 block4a_project_conv (Conv  (None, None, None, 80)       19200     [&#39;block4a_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block4a_project_bn (BatchN  (None, None, None, 80)       320       [&#39;block4a_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block4b_expand_conv (Conv2  (None, None, None, 480)      38400     [&#39;block4a_project_bn[0][0]&#39;]  
 D)                                                                                               
                                                                                                  
 block4b_expand_bn (BatchNo  (None, None, None, 480)      1920      [&#39;block4b_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block4b_expand_activation   (None, None, None, 480)      0         [&#39;block4b_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block4b_dwconv (DepthwiseC  (None, None, None, 480)      4320      [&#39;block4b_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block4b_bn (BatchNormaliza  (None, None, None, 480)      1920      [&#39;block4b_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block4b_activation (Activa  (None, None, None, 480)      0         [&#39;block4b_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block4b_se_squeeze (Global  (None, 480)                  0         [&#39;block4b_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block4b_se_reshape (Reshap  (None, 1, 1, 480)            0         [&#39;block4b_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block4b_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      [&#39;block4b_se_reshape[0][0]&#39;]  
                                                                                                  
 block4b_se_expand (Conv2D)  (None, 1, 1, 480)            10080     [&#39;block4b_se_reduce[0][0]&#39;]   
                                                                                                  
 block4b_se_excite (Multipl  (None, None, None, 480)      0         [&#39;block4b_activation[0][0]&#39;,  
 y)                                                                  &#39;block4b_se_expand[0][0]&#39;]   
                                                                                                  
 block4b_project_conv (Conv  (None, None, None, 80)       38400     [&#39;block4b_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block4b_project_bn (BatchN  (None, None, None, 80)       320       [&#39;block4b_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block4b_drop (Dropout)      (None, None, None, 80)       0         [&#39;block4b_project_bn[0][0]&#39;]  
                                                                                                  
 block4b_add (Add)           (None, None, None, 80)       0         [&#39;block4b_drop[0][0]&#39;,        
                                                                     &#39;block4a_project_bn[0][0]&#39;]  
                                                                                                  
 block4c_expand_conv (Conv2  (None, None, None, 480)      38400     [&#39;block4b_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block4c_expand_bn (BatchNo  (None, None, None, 480)      1920      [&#39;block4c_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block4c_expand_activation   (None, None, None, 480)      0         [&#39;block4c_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block4c_dwconv (DepthwiseC  (None, None, None, 480)      4320      [&#39;block4c_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block4c_bn (BatchNormaliza  (None, None, None, 480)      1920      [&#39;block4c_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block4c_activation (Activa  (None, None, None, 480)      0         [&#39;block4c_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block4c_se_squeeze (Global  (None, 480)                  0         [&#39;block4c_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block4c_se_reshape (Reshap  (None, 1, 1, 480)            0         [&#39;block4c_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block4c_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      [&#39;block4c_se_reshape[0][0]&#39;]  
                                                                                                  
 block4c_se_expand (Conv2D)  (None, 1, 1, 480)            10080     [&#39;block4c_se_reduce[0][0]&#39;]   
                                                                                                  
 block4c_se_excite (Multipl  (None, None, None, 480)      0         [&#39;block4c_activation[0][0]&#39;,  
 y)                                                                  &#39;block4c_se_expand[0][0]&#39;]   
                                                                                                  
 block4c_project_conv (Conv  (None, None, None, 80)       38400     [&#39;block4c_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block4c_project_bn (BatchN  (None, None, None, 80)       320       [&#39;block4c_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block4c_drop (Dropout)      (None, None, None, 80)       0         [&#39;block4c_project_bn[0][0]&#39;]  
                                                                                                  
 block4c_add (Add)           (None, None, None, 80)       0         [&#39;block4c_drop[0][0]&#39;,        
                                                                     &#39;block4b_add[0][0]&#39;]         
                                                                                                  
 block5a_expand_conv (Conv2  (None, None, None, 480)      38400     [&#39;block4c_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block5a_expand_bn (BatchNo  (None, None, None, 480)      1920      [&#39;block5a_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block5a_expand_activation   (None, None, None, 480)      0         [&#39;block5a_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block5a_dwconv (DepthwiseC  (None, None, None, 480)      12000     [&#39;block5a_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block5a_bn (BatchNormaliza  (None, None, None, 480)      1920      [&#39;block5a_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block5a_activation (Activa  (None, None, None, 480)      0         [&#39;block5a_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block5a_se_squeeze (Global  (None, 480)                  0         [&#39;block5a_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block5a_se_reshape (Reshap  (None, 1, 1, 480)            0         [&#39;block5a_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block5a_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      [&#39;block5a_se_reshape[0][0]&#39;]  
                                                                                                  
 block5a_se_expand (Conv2D)  (None, 1, 1, 480)            10080     [&#39;block5a_se_reduce[0][0]&#39;]   
                                                                                                  
 block5a_se_excite (Multipl  (None, None, None, 480)      0         [&#39;block5a_activation[0][0]&#39;,  
 y)                                                                  &#39;block5a_se_expand[0][0]&#39;]   
                                                                                                  
 block5a_project_conv (Conv  (None, None, None, 112)      53760     [&#39;block5a_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block5a_project_bn (BatchN  (None, None, None, 112)      448       [&#39;block5a_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block5b_expand_conv (Conv2  (None, None, None, 672)      75264     [&#39;block5a_project_bn[0][0]&#39;]  
 D)                                                                                               
                                                                                                  
 block5b_expand_bn (BatchNo  (None, None, None, 672)      2688      [&#39;block5b_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block5b_expand_activation   (None, None, None, 672)      0         [&#39;block5b_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block5b_dwconv (DepthwiseC  (None, None, None, 672)      16800     [&#39;block5b_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block5b_bn (BatchNormaliza  (None, None, None, 672)      2688      [&#39;block5b_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block5b_activation (Activa  (None, None, None, 672)      0         [&#39;block5b_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block5b_se_squeeze (Global  (None, 672)                  0         [&#39;block5b_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block5b_se_reshape (Reshap  (None, 1, 1, 672)            0         [&#39;block5b_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block5b_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     [&#39;block5b_se_reshape[0][0]&#39;]  
                                                                                                  
 block5b_se_expand (Conv2D)  (None, 1, 1, 672)            19488     [&#39;block5b_se_reduce[0][0]&#39;]   
                                                                                                  
 block5b_se_excite (Multipl  (None, None, None, 672)      0         [&#39;block5b_activation[0][0]&#39;,  
 y)                                                                  &#39;block5b_se_expand[0][0]&#39;]   
                                                                                                  
 block5b_project_conv (Conv  (None, None, None, 112)      75264     [&#39;block5b_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block5b_project_bn (BatchN  (None, None, None, 112)      448       [&#39;block5b_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block5b_drop (Dropout)      (None, None, None, 112)      0         [&#39;block5b_project_bn[0][0]&#39;]  
                                                                                                  
 block5b_add (Add)           (None, None, None, 112)      0         [&#39;block5b_drop[0][0]&#39;,        
                                                                     &#39;block5a_project_bn[0][0]&#39;]  
                                                                                                  
 block5c_expand_conv (Conv2  (None, None, None, 672)      75264     [&#39;block5b_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block5c_expand_bn (BatchNo  (None, None, None, 672)      2688      [&#39;block5c_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block5c_expand_activation   (None, None, None, 672)      0         [&#39;block5c_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block5c_dwconv (DepthwiseC  (None, None, None, 672)      16800     [&#39;block5c_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block5c_bn (BatchNormaliza  (None, None, None, 672)      2688      [&#39;block5c_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block5c_activation (Activa  (None, None, None, 672)      0         [&#39;block5c_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block5c_se_squeeze (Global  (None, 672)                  0         [&#39;block5c_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block5c_se_reshape (Reshap  (None, 1, 1, 672)            0         [&#39;block5c_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block5c_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     [&#39;block5c_se_reshape[0][0]&#39;]  
                                                                                                  
 block5c_se_expand (Conv2D)  (None, 1, 1, 672)            19488     [&#39;block5c_se_reduce[0][0]&#39;]   
                                                                                                  
 block5c_se_excite (Multipl  (None, None, None, 672)      0         [&#39;block5c_activation[0][0]&#39;,  
 y)                                                                  &#39;block5c_se_expand[0][0]&#39;]   
                                                                                                  
 block5c_project_conv (Conv  (None, None, None, 112)      75264     [&#39;block5c_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block5c_project_bn (BatchN  (None, None, None, 112)      448       [&#39;block5c_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block5c_drop (Dropout)      (None, None, None, 112)      0         [&#39;block5c_project_bn[0][0]&#39;]  
                                                                                                  
 block5c_add (Add)           (None, None, None, 112)      0         [&#39;block5c_drop[0][0]&#39;,        
                                                                     &#39;block5b_add[0][0]&#39;]         
                                                                                                  
 block6a_expand_conv (Conv2  (None, None, None, 672)      75264     [&#39;block5c_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block6a_expand_bn (BatchNo  (None, None, None, 672)      2688      [&#39;block6a_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block6a_expand_activation   (None, None, None, 672)      0         [&#39;block6a_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block6a_dwconv_pad (ZeroPa  (None, None, None, 672)      0         [&#39;block6a_expand_activation[0]
 dding2D)                                                           [0]&#39;]                         
                                                                                                  
 block6a_dwconv (DepthwiseC  (None, None, None, 672)      16800     [&#39;block6a_dwconv_pad[0][0]&#39;]  
 onv2D)                                                                                           
                                                                                                  
 block6a_bn (BatchNormaliza  (None, None, None, 672)      2688      [&#39;block6a_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block6a_activation (Activa  (None, None, None, 672)      0         [&#39;block6a_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block6a_se_squeeze (Global  (None, 672)                  0         [&#39;block6a_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block6a_se_reshape (Reshap  (None, 1, 1, 672)            0         [&#39;block6a_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block6a_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     [&#39;block6a_se_reshape[0][0]&#39;]  
                                                                                                  
 block6a_se_expand (Conv2D)  (None, 1, 1, 672)            19488     [&#39;block6a_se_reduce[0][0]&#39;]   
                                                                                                  
 block6a_se_excite (Multipl  (None, None, None, 672)      0         [&#39;block6a_activation[0][0]&#39;,  
 y)                                                                  &#39;block6a_se_expand[0][0]&#39;]   
                                                                                                  
 block6a_project_conv (Conv  (None, None, None, 192)      129024    [&#39;block6a_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block6a_project_bn (BatchN  (None, None, None, 192)      768       [&#39;block6a_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block6b_expand_conv (Conv2  (None, None, None, 1152)     221184    [&#39;block6a_project_bn[0][0]&#39;]  
 D)                                                                                               
                                                                                                  
 block6b_expand_bn (BatchNo  (None, None, None, 1152)     4608      [&#39;block6b_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block6b_expand_activation   (None, None, None, 1152)     0         [&#39;block6b_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block6b_dwconv (DepthwiseC  (None, None, None, 1152)     28800     [&#39;block6b_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block6b_bn (BatchNormaliza  (None, None, None, 1152)     4608      [&#39;block6b_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block6b_activation (Activa  (None, None, None, 1152)     0         [&#39;block6b_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block6b_se_squeeze (Global  (None, 1152)                 0         [&#39;block6b_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block6b_se_reshape (Reshap  (None, 1, 1, 1152)           0         [&#39;block6b_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block6b_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     [&#39;block6b_se_reshape[0][0]&#39;]  
                                                                                                  
 block6b_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     [&#39;block6b_se_reduce[0][0]&#39;]   
                                                                                                  
 block6b_se_excite (Multipl  (None, None, None, 1152)     0         [&#39;block6b_activation[0][0]&#39;,  
 y)                                                                  &#39;block6b_se_expand[0][0]&#39;]   
                                                                                                  
 block6b_project_conv (Conv  (None, None, None, 192)      221184    [&#39;block6b_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block6b_project_bn (BatchN  (None, None, None, 192)      768       [&#39;block6b_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block6b_drop (Dropout)      (None, None, None, 192)      0         [&#39;block6b_project_bn[0][0]&#39;]  
                                                                                                  
 block6b_add (Add)           (None, None, None, 192)      0         [&#39;block6b_drop[0][0]&#39;,        
                                                                     &#39;block6a_project_bn[0][0]&#39;]  
                                                                                                  
 block6c_expand_conv (Conv2  (None, None, None, 1152)     221184    [&#39;block6b_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block6c_expand_bn (BatchNo  (None, None, None, 1152)     4608      [&#39;block6c_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block6c_expand_activation   (None, None, None, 1152)     0         [&#39;block6c_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block6c_dwconv (DepthwiseC  (None, None, None, 1152)     28800     [&#39;block6c_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block6c_bn (BatchNormaliza  (None, None, None, 1152)     4608      [&#39;block6c_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block6c_activation (Activa  (None, None, None, 1152)     0         [&#39;block6c_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block6c_se_squeeze (Global  (None, 1152)                 0         [&#39;block6c_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block6c_se_reshape (Reshap  (None, 1, 1, 1152)           0         [&#39;block6c_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block6c_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     [&#39;block6c_se_reshape[0][0]&#39;]  
                                                                                                  
 block6c_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     [&#39;block6c_se_reduce[0][0]&#39;]   
                                                                                                  
 block6c_se_excite (Multipl  (None, None, None, 1152)     0         [&#39;block6c_activation[0][0]&#39;,  
 y)                                                                  &#39;block6c_se_expand[0][0]&#39;]   
                                                                                                  
 block6c_project_conv (Conv  (None, None, None, 192)      221184    [&#39;block6c_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block6c_project_bn (BatchN  (None, None, None, 192)      768       [&#39;block6c_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block6c_drop (Dropout)      (None, None, None, 192)      0         [&#39;block6c_project_bn[0][0]&#39;]  
                                                                                                  
 block6c_add (Add)           (None, None, None, 192)      0         [&#39;block6c_drop[0][0]&#39;,        
                                                                     &#39;block6b_add[0][0]&#39;]         
                                                                                                  
 block6d_expand_conv (Conv2  (None, None, None, 1152)     221184    [&#39;block6c_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block6d_expand_bn (BatchNo  (None, None, None, 1152)     4608      [&#39;block6d_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block6d_expand_activation   (None, None, None, 1152)     0         [&#39;block6d_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block6d_dwconv (DepthwiseC  (None, None, None, 1152)     28800     [&#39;block6d_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block6d_bn (BatchNormaliza  (None, None, None, 1152)     4608      [&#39;block6d_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block6d_activation (Activa  (None, None, None, 1152)     0         [&#39;block6d_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block6d_se_squeeze (Global  (None, 1152)                 0         [&#39;block6d_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block6d_se_reshape (Reshap  (None, 1, 1, 1152)           0         [&#39;block6d_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block6d_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     [&#39;block6d_se_reshape[0][0]&#39;]  
                                                                                                  
 block6d_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     [&#39;block6d_se_reduce[0][0]&#39;]   
                                                                                                  
 block6d_se_excite (Multipl  (None, None, None, 1152)     0         [&#39;block6d_activation[0][0]&#39;,  
 y)                                                                  &#39;block6d_se_expand[0][0]&#39;]   
                                                                                                  
 block6d_project_conv (Conv  (None, None, None, 192)      221184    [&#39;block6d_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block6d_project_bn (BatchN  (None, None, None, 192)      768       [&#39;block6d_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 block6d_drop (Dropout)      (None, None, None, 192)      0         [&#39;block6d_project_bn[0][0]&#39;]  
                                                                                                  
 block6d_add (Add)           (None, None, None, 192)      0         [&#39;block6d_drop[0][0]&#39;,        
                                                                     &#39;block6c_add[0][0]&#39;]         
                                                                                                  
 block7a_expand_conv (Conv2  (None, None, None, 1152)     221184    [&#39;block6d_add[0][0]&#39;]         
 D)                                                                                               
                                                                                                  
 block7a_expand_bn (BatchNo  (None, None, None, 1152)     4608      [&#39;block7a_expand_conv[0][0]&#39;] 
 rmalization)                                                                                     
                                                                                                  
 block7a_expand_activation   (None, None, None, 1152)     0         [&#39;block7a_expand_bn[0][0]&#39;]   
 (Activation)                                                                                     
                                                                                                  
 block7a_dwconv (DepthwiseC  (None, None, None, 1152)     10368     [&#39;block7a_expand_activation[0]
 onv2D)                                                             [0]&#39;]                         
                                                                                                  
 block7a_bn (BatchNormaliza  (None, None, None, 1152)     4608      [&#39;block7a_dwconv[0][0]&#39;]      
 tion)                                                                                            
                                                                                                  
 block7a_activation (Activa  (None, None, None, 1152)     0         [&#39;block7a_bn[0][0]&#39;]          
 tion)                                                                                            
                                                                                                  
 block7a_se_squeeze (Global  (None, 1152)                 0         [&#39;block7a_activation[0][0]&#39;]  
 AveragePooling2D)                                                                                
                                                                                                  
 block7a_se_reshape (Reshap  (None, 1, 1, 1152)           0         [&#39;block7a_se_squeeze[0][0]&#39;]  
 e)                                                                                               
                                                                                                  
 block7a_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     [&#39;block7a_se_reshape[0][0]&#39;]  
                                                                                                  
 block7a_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     [&#39;block7a_se_reduce[0][0]&#39;]   
                                                                                                  
 block7a_se_excite (Multipl  (None, None, None, 1152)     0         [&#39;block7a_activation[0][0]&#39;,  
 y)                                                                  &#39;block7a_se_expand[0][0]&#39;]   
                                                                                                  
 block7a_project_conv (Conv  (None, None, None, 320)      368640    [&#39;block7a_se_excite[0][0]&#39;]   
 2D)                                                                                              
                                                                                                  
 block7a_project_bn (BatchN  (None, None, None, 320)      1280      [&#39;block7a_project_conv[0][0]&#39;]
 ormalization)                                                                                    
                                                                                                  
 top_conv (Conv2D)           (None, None, None, 1280)     409600    [&#39;block7a_project_bn[0][0]&#39;]  
                                                                                                  
 top_bn (BatchNormalization  (None, None, None, 1280)     5120      [&#39;top_conv[0][0]&#39;]            
 )                                                                                                
                                                                                                  
 top_activation (Activation  (None, None, None, 1280)     0         [&#39;top_bn[0][0]&#39;]              
 )                                                                                                
                                                                                                  
==================================================================================================
Total params: 4049571 (15.45 MB)
Trainable params: 0 (0.00 Byte)
Non-trainable params: 4049571 (15.45 MB)
__________________________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot our complete model</span>
<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">model_0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3b479083a80a34e7799e4bad2bb1a73739e1322b8a83f76f6c14dd2458275f24.png" src="_images/3b479083a80a34e7799e4bad2bb1a73739e1322b8a83f76f6c14dd2458275f24.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check our constructed model&#39;s summary</span>
<span class="n">model_0</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_layer (InputLayer)    [(None, 224, 224, 3)]     0         
                                                                 
 efficientnetb0 (Functional  (None, None, None, 1280   4049571   
 )                           )                                   
                                                                 
 global_avg_pooling_layer (  (None, 1280)              0         
 GlobalAveragePooling2D)                                         
                                                                 
 output_layer (Dense)        (None, 10)                12810     
                                                                 
=================================================================
Total params: 4062381 (15.50 MB)
Trainable params: 12810 (50.04 KB)
Non-trainable params: 4049571 (15.45 MB)
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">plot_loss_curves</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns separate loss curves for training and validation metrics.</span>

<span class="sd">  Args:</span>
<span class="sd">    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
  <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
  <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>

  <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]))</span>

  <span class="c1"># Plot loss</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

  <span class="c1"># Plot accuracy</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>

<span class="c1"># Plot loss curves</span>
<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">history_0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5780403b639bc391adf5bc1295a977a742eb44c220b06e17d0564aeb25f1d2ec.png" src="_images/5780403b639bc391adf5bc1295a977a742eb44c220b06e17d0564aeb25f1d2ec.png" />
<img alt="_images/e51f3b1dab0a558dd678cb265cc9fba7fbeebbedb7e79f582fba5ae6e963407d.png" src="_images/e51f3b1dab0a558dd678cb265cc9fba7fbeebbedb7e79f582fba5ae6e963407d.png" />
</div>
</div>
<section id="experimentation">
<h3>Experimentation<a class="headerlink" href="#experimentation" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Model 1</strong>: Use transfer learning on 1% of training data with data augumentation</p></li>
<li><p><strong>Model 2</strong>: Fine tune a transfer learning model on 100% of training data with data augumentation</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download 1% of training data</span>
<span class="o">!</span>wget<span class="w"> </span>https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip

<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="n">zipref</span> <span class="o">=</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="s1">&#39;10_food_classes_1_percent.zip&#39;</span><span class="p">)</span>
<span class="n">zipref</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
<span class="n">zipref</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--2024-03-21 19:24:50--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.215.207, 172.217.193.207, 172.217.204.207, ...
Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.215.207|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 133612354 (127M) [application/zip]
Saving to: 10_food_classes_1_percent.zip

10_food_classes_1_p 100%[===================&gt;] 127.42M   139MB/s    in 0.9s    

2024-03-21 19:24:51 (139 MB/s) - 10_food_classes_1_percent.zip saved [133612354/133612354]
</pre></div>
</div>
</div>
</div>
<section id="model-1">
<h4>Model 1<a class="headerlink" href="#model-1" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training and test data dir</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="s1">&#39;10_food_classes_1_percent/train&#39;</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="s1">&#39;10_food_classes_1_percent/test&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Walk through our 1% data dir</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">walk_through_dir</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">dirpath</span><span class="p">,</span> <span class="n">dirnames</span><span class="p">,</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dirnames</span><span class="p">)</span><span class="si">}</span><span class="s1"> directories and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">)</span><span class="si">}</span><span class="s1"> files in &quot;</span><span class="si">{</span><span class="n">dirpath</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)</span>

<span class="n">walk_through_dir</span><span class="p">(</span><span class="s1">&#39;10_food_classes_1_percent&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>There are 2 directories and 0 files in &quot;10_food_classes_1_percent&quot;
There are 10 directories and 0 files in &quot;10_food_classes_1_percent/train&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/sushi&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/grilled_salmon&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/chicken_curry&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/chicken_wings&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/ramen&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/pizza&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/hamburger&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/fried_rice&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/steak&quot;
There are 0 directories and 7 files in &quot;10_food_classes_1_percent/train/ice_cream&quot;
There are 10 directories and 0 files in &quot;10_food_classes_1_percent/test&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/sushi&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/grilled_salmon&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/chicken_curry&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/chicken_wings&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/ramen&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/pizza&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/hamburger&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/fried_rice&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/steak&quot;
There are 0 directories and 250 files in &quot;10_food_classes_1_percent/test/ice_cream&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load train and test data</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">IMG_SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
                                                                 <span class="n">image_size</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="p">,</span>
                                                                 <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
                                                                <span class="n">image_size</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="p">,</span>
                                                                <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                                                <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 70 files belonging to 10 classes.
Found 2500 files belonging to 10 classes.
</pre></div>
</div>
</div>
</div>
<p>Add data augumentation layer directly into the model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data augumentation layer</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="n">data_augumentation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="s1">&#39;horizontal&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomHeight</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomWidth</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;data_augumentation&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># View random image</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="nn">mpimg</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="n">target_class</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">class_names</span><span class="p">)</span>
<span class="n">target_dir</span> <span class="o">=</span> <span class="n">train_dir</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">target_class</span>

<span class="n">random_img</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">target_dir</span><span class="p">))</span>
<span class="n">random_img_path</span> <span class="o">=</span> <span class="n">target_dir</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">random_img</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">mpimg</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">random_img_path</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Original image for </span><span class="si">{</span><span class="n">target_class</span><span class="si">}</span><span class="s1"> class&#39;</span><span class="p">)</span>

<span class="c1"># Augument the image</span>
<span class="n">img_aug</span> <span class="o">=</span> <span class="n">data_augumentation</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">img_aug</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="mf">255.</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Image after augumentation&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Image after augumentation&#39;)
</pre></div>
</div>
<img alt="_images/56e935e1995350c5d4073045ec2cfbb9659a415b7f16b30543cbc8b670725e85.png" src="_images/56e935e1995350c5d4073045ec2cfbb9659a415b7f16b30543cbc8b670725e85.png" />
<img alt="_images/8c1ad28a13661d77d896ed60a7185a8b3140dd5138e928e090ad5fc442f9906c.png" src="_images/8c1ad28a13661d77d896ed60a7185a8b3140dd5138e928e090ad5fc442f9906c.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a model</span>

<span class="c1">## Setup input shape and base model</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">efficientnet_v2</span><span class="o">.</span><span class="n">EfficientNetV2B0</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1">## Create input layer</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_layer&#39;</span><span class="p">)</span>

<span class="c1">## Add data augumentation layer</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data_augumentation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="c1">## Give input to base model</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">## Pool features of base model</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;global_avg_pooling&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">## Dense layer as output</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_layer&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">## Make a model</span>
<span class="n">model_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>

<span class="c1">## Compile  the model</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1">## Fit the model</span>
<span class="n">history_1</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span>
                        <span class="n">validation_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                        <span class="n">validation_steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5
24274472/24274472 [==============================] - 0s 0us/step
Epoch 1/5
2/2 [==============================] - 226s 205s/step - loss: 2.4856 - accuracy: 0.1000 - val_loss: 2.3406 - val_accuracy: 0.0960
Epoch 2/5
2/2 [==============================] - 208s 202s/step - loss: 2.2937 - accuracy: 0.1429 - val_loss: 2.2553 - val_accuracy: 0.1412
Epoch 3/5
2/2 [==============================] - 205s 202s/step - loss: 2.1417 - accuracy: 0.2429 - val_loss: 2.1824 - val_accuracy: 0.1868
Epoch 4/5
2/2 [==============================] - 208s 202s/step - loss: 2.0312 - accuracy: 0.3000 - val_loss: 2.1196 - val_accuracy: 0.2308
Epoch 5/5
2/2 [==============================] - 165s 161s/step - loss: 2.0019 - accuracy: 0.3429 - val_loss: 2.0607 - val_accuracy: 0.2820
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Models summary</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_layer (InputLayer)    [(None, 224, 224, 3)]     0         
                                                                 
 data_augumentation (Sequen  (None, None, None, 3)     0         
 tial)                                                           
                                                                 
 efficientnetv2-b0 (Functio  (None, None, None, 1280   5919312   
 nal)                        )                                   
                                                                 
 global_avg_pooling (Global  (None, 1280)              0         
 AveragePooling2D)                                               
                                                                 
 output_layer (Dense)        (None, 10)                12810     
                                                                 
=================================================================
Total params: 5932122 (22.63 MB)
Trainable params: 12810 (50.04 KB)
Non-trainable params: 5919312 (22.58 MB)
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot loss curves</span>

<span class="k">def</span> <span class="nf">plot_loss_curves</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
  <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
  <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>

  <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]))</span>

  <span class="c1"># Plot loss</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

  <span class="c1"># Plot accuracy</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>

<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">history_1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9255ccbe17f60fc34bd32c5da4e0eda312353394f6e9538fbda526a6a09c863f.png" src="_images/9255ccbe17f60fc34bd32c5da4e0eda312353394f6e9538fbda526a6a09c863f.png" />
<img alt="_images/26cfdfde9a78b1202a8dfbca7a65c29a10959d6f20fd7365e0dd318bdc7e6561.png" src="_images/26cfdfde9a78b1202a8dfbca7a65c29a10959d6f20fd7365e0dd318bdc7e6561.png" />
</div>
</div>
</section>
<section id="model-2">
<h4>Model 2<a class="headerlink" href="#model-2" title="Permalink to this heading">#</a></h4>
<p>Fine Tunning model using 100% data of 10 food classes</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setup data directories</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train&#39;</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check number of images in each class</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">walk_through_dir</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">dirpath</span><span class="p">,</span> <span class="n">dirnames</span><span class="p">,</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dirnames</span><span class="p">)</span><span class="si">}</span><span class="s1"> directories and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">filenames</span><span class="p">)</span><span class="si">}</span><span class="s1"> files in &quot;</span><span class="si">{</span><span class="n">dirpath</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">)</span>

<span class="n">walk_through_dir</span><span class="p">(</span><span class="s1">&#39;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>There are 2 directories and 0 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data&quot;
There are 10 directories and 0 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/ice_cream&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/chicken_curry&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/steak&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/sushi&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/chicken_wings&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/grilled_salmon&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/hamburger&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/pizza&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/ramen&quot;
There are 0 directories and 250 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/test/fried_rice&quot;
There are 10 directories and 0 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/ice_cream&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/chicken_curry&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/steak&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/sushi&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/chicken_wings&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/grilled_salmon&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/hamburger&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/pizza&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/ramen&quot;
There are 0 directories and 750 files in &quot;/content/drive/MyDrive/Colab Notebooks/10_food_classes_all_data/train/fried_rice&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setup data inputs</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">IMG_SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># This will make tf.Data.Datasets</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
                                                                 <span class="n">image_size</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="p">,</span>
                                                                 <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
                                                                <span class="n">image_size</span><span class="o">=</span><span class="n">IMG_SHAPE</span><span class="p">,</span>
                                                                <span class="n">label_mode</span><span class="o">=</span><span class="s1">&#39;categorical&#39;</span><span class="p">,</span>
                                                                <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Found 7500 files belonging to 10 classes.
Found 2500 files belonging to 10 classes.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_data</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(64, 224, 224, 3) (64, 10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a functional model with data augumentation</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="n">data_augumentation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="s1">&#39;horizontal&#39;</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomHeight</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">RandomWidth</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
<span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;data_augumentation&#39;</span><span class="p">)</span>

<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Create a base model and make last 10 layers trainable</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">efficientnet_v2</span><span class="o">.</span><span class="n">EfficientNetV2B0</span><span class="p">(</span><span class="n">include_top</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">base_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">10</span><span class="p">]:</span> <span class="c1"># Freeze all layers except last 10 layers</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5
24274472/24274472 [==============================] - 0s 0us/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">base_model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10
</pre></div>
</div>
</div>
</div>
<p>The ModelCheckpoint callback gives you the ability to save your model, as a whole in the SavedModel format or the weights (patterns) only to a specified directory as it trains.</p>
<p>This is helpful if you think your model is going to be training for a long time and you want to make backups of it as it trains.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setup checkpoint path</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="s1">&#39;model2/checkpoints.ckpt&#39;</span>

<span class="c1"># Create a ModelCheckpoint callback that saves model&#39;s weight only</span>
<span class="n">checkpoint_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">checkpoint_path</span><span class="p">,</span>
                                                         <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                         <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                         <span class="n">save_freq</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
                                                         <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create Model 2&#39;s input and output layers</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_layer&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data_augumentation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># keep base model into inferance mode, so batch norm layer&#39;s don&#39;t get updated</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;global_avg_pooling&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_layer&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

<span class="c1"># Compile</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit the model and save checkpoints</span>
<span class="n">initial_epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">history_model_2</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                              <span class="n">epochs</span><span class="o">=</span><span class="n">initial_epochs</span><span class="p">,</span>
                              <span class="n">validation_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                              <span class="n">validation_steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span>
                              <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_callback</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
118/118 [==============================] - ETA: 0s - loss: 2.3230 - accuracy: 0.0963
Epoch 1: val_loss improved from inf to 2.31491, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 1515s 13s/step - loss: 2.3230 - accuracy: 0.0963 - val_loss: 2.3149 - val_accuracy: 0.1000
Epoch 2/5
118/118 [==============================] - ETA: 0s - loss: 2.3163 - accuracy: 0.0984
Epoch 2: val_loss improved from 2.31491 to 2.30761, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 130s 1s/step - loss: 2.3163 - accuracy: 0.0984 - val_loss: 2.3076 - val_accuracy: 0.1000
Epoch 3/5
118/118 [==============================] - ETA: 0s - loss: 2.3072 - accuracy: 0.0945
Epoch 3: val_loss improved from 2.30761 to 2.30287, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 126s 1s/step - loss: 2.3072 - accuracy: 0.0945 - val_loss: 2.3029 - val_accuracy: 0.1000
Epoch 4/5
118/118 [==============================] - ETA: 0s - loss: 2.3045 - accuracy: 0.0899
Epoch 4: val_loss improved from 2.30287 to 2.30278, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 108s 897ms/step - loss: 2.3045 - accuracy: 0.0899 - val_loss: 2.3028 - val_accuracy: 0.1000
Epoch 5/5
118/118 [==============================] - ETA: 0s - loss: 2.3038 - accuracy: 0.0921
Epoch 5: val_loss improved from 2.30278 to 2.30264, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 102s 852ms/step - loss: 2.3038 - accuracy: 0.0921 - val_loss: 2.3026 - val_accuracy: 0.1000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Total trainable variables in our model</span>
<span class="nb">len</span><span class="p">(</span><span class="n">model_2</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>12
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_layer (InputLayer)    [(None, 224, 224, 3)]     0         
                                                                 
 data_augumentation (Sequen  (None, None, None, 3)     0         
 tial)                                                           
                                                                 
 efficientnetv2-b0 (Functio  (None, None, None, 1280   5919312   
 nal)                        )                                   
                                                                 
 global_avg_pooling (Global  (None, 1280)              0         
 AveragePooling2D)                                               
                                                                 
 output_layer (Dense)        (None, 10)                12810     
                                                                 
=================================================================
Total params: 5932122 (22.63 MB)
Trainable params: 594490 (2.27 MB)
Non-trainable params: 5337632 (20.36 MB)
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check which layers are tuneable in the whole model</span>
<span class="k">for</span> <span class="n">layer_number</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model_2</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">layer_number</span><span class="si">}</span><span class="s1"> Layer Name: </span><span class="si">{</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1"> | Trainable: </span><span class="si">{</span><span class="n">layer</span><span class="o">.</span><span class="n">trainable</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0 Layer Name: input_layer | Trainable: True
1 Layer Name: data_augumentation | Trainable: True
2 Layer Name: efficientnetv2-b0 | Trainable: True
3 Layer Name: global_avg_pooling | Trainable: True
4 Layer Name: output_layer | Trainable: True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot loss curves</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">plot_loss_curves</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
  <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

  <span class="n">accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
  <span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>

  <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]))</span>

  <span class="c1"># Plot loss</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

  <span class="c1"># Plot accuracy</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training_accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>

<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">history_model_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/49d51c59773979fc916056b04f59c3a7e00ac4a00cf1fb0464cb511054a43d8a.png" src="_images/49d51c59773979fc916056b04f59c3a7e00ac4a00cf1fb0464cb511054a43d8a.png" />
<img alt="_images/66a6f6b646163d5cf536ad2d7eff5d8a5c654ad0f9af9aae07b129180ef1aaa1.png" src="_images/66a6f6b646163d5cf536ad2d7eff5d8a5c654ad0f9af9aae07b129180ef1aaa1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run for another 5 epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="n">initial_epochs</span> <span class="o">+</span> <span class="mi">5</span>

<span class="c1"># Refit the model</span>
<span class="n">history_model_2_fine</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                                   <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                                   <span class="n">validation_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                                   <span class="n">initial_epoch</span><span class="o">=</span><span class="n">history_model_2</span><span class="o">.</span><span class="n">epoch</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                   <span class="n">validation_steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span>
                                   <span class="n">callbacks</span><span class="o">=</span><span class="n">checkpoint_callback</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5/10
118/118 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.0967
Epoch 5: val_loss improved from 2.30264 to 2.30260, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 98s 816ms/step - loss: 2.3032 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 6/10
118/118 [==============================] - ETA: 0s - loss: 2.3031 - accuracy: 0.0928
Epoch 6: val_loss improved from 2.30260 to 2.30259, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 96s 800ms/step - loss: 2.3031 - accuracy: 0.0928 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 7/10
118/118 [==============================] - ETA: 0s - loss: 2.3030 - accuracy: 0.0956
Epoch 7: val_loss improved from 2.30259 to 2.30259, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 85s 706ms/step - loss: 2.3030 - accuracy: 0.0956 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 8/10
118/118 [==============================] - ETA: 0s - loss: 2.3028 - accuracy: 0.0917
Epoch 8: val_loss improved from 2.30259 to 2.30258, saving model to model2/checkpoints.ckpt
118/118 [==============================] - 82s 673ms/step - loss: 2.3028 - accuracy: 0.0917 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 9/10
118/118 [==============================] - ETA: 0s - loss: 2.3028 - accuracy: 0.0955
Epoch 9: val_loss did not improve from 2.30258
118/118 [==============================] - 76s 630ms/step - loss: 2.3028 - accuracy: 0.0955 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 10/10
118/118 [==============================] - ETA: 0s - loss: 2.3027 - accuracy: 0.0996
Epoch 10: val_loss did not improve from 2.30258
118/118 [==============================] - 70s 577ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compare_historys</span><span class="p">(</span><span class="n">original_history</span><span class="p">,</span> <span class="n">new_history</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compares two model history objects.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get original history measurements</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">original_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">original_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span>
    <span class="n">initial_epochs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>

    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">original_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">]</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">original_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span>

    <span class="c1"># Combine original history with new history</span>
    <span class="n">total_acc</span> <span class="o">=</span> <span class="n">acc</span> <span class="o">+</span> <span class="n">new_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="n">new_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span>

    <span class="n">total_val_acc</span> <span class="o">=</span> <span class="n">val_acc</span> <span class="o">+</span> <span class="n">new_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">]</span>
    <span class="n">total_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span> <span class="o">+</span> <span class="n">new_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">total_acc</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">total_acc</span><span class="p">)</span>

    <span class="c1"># Make plots</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Accuracy&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_val_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">initial_epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">initial_epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
              <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Start Fine Tuning&#39;</span><span class="p">)</span> <span class="c1"># reshift plot around epochs</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and Validation Accuracy&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">total_val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">initial_epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">initial_epochs</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
              <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Start Fine Tuning&#39;</span><span class="p">)</span> <span class="c1"># reshift plot around epochs</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and Validation Loss&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compare_historys</span><span class="p">(</span><span class="n">original_history</span><span class="o">=</span><span class="n">history_model_2</span><span class="p">,</span>
                 <span class="n">new_history</span><span class="o">=</span><span class="n">history_model_2_fine</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5
11
[0.09626666456460953, 0.09839999675750732, 0.09453333169221878, 0.08986666798591614, 0.09213333576917648, 0.09666666388511658, 0.09279999881982803, 0.09560000151395798, 0.09173333644866943, 0.09546666592359543, 0.09960000216960907]
</pre></div>
</div>
<img alt="_images/b5e154883ec86f577e6bd60304f7104e9a0c0aff62f58304055399ae52aadc93.png" src="_images/b5e154883ec86f577e6bd60304f7104e9a0c0aff62f58304055399ae52aadc93.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate our model</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>40/40 [==============================] - 10s 217ms/step - loss: 2.3026 - accuracy: 0.1000
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2.302581548690796, 0.10000000149011612]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load in saved model weights and evaluate model</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
<span class="n">loaded_weights_model_results</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>40/40 [==============================] - 11s 228ms/step - loss: 2.3026 - accuracy: 0.1000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check if results of our native model and loaded models are same</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">results</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">loaded_weights_model_results</span><span class="p">)))</span> <span class="c1"># Check if results are very close</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span> <span class="o">==</span> <span class="n">loaded_weights_model_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ True  True]
False
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Tensorflow.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tensorflow</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">Feature Extraction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-dataset">Exploring Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-loader-preparing-the-data">Data loader (preparing the data)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-callbacks-things-to-run-whilst-our-model-train">Setting up callbacks (things to run whilst our model train</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-model-using-tensorflow-hub">Create model using TensorFlow Hub</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning">Fine Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experimentation">Experimentation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-1">Model 1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-2">Model 2</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Shivesh Singh
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>